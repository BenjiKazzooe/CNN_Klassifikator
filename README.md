# ğŸ§µ Fashion-MNIST CNN Klassifikator

Dieses Projekt nutzt ein **Convolutional Neural Network (CNN)** zur Klassifikation von Bildern aus dem **Fashion-MNIST-Datensatz**. Die Daten werden von Kaggle heruntergeladen, verarbeitet und fÃ¼r das Training eines CNN-Modells verwendet. Ziel ist es, KleidungsstÃ¼cke wie T-Shirts, Hosen oder Schuhe anhand ihrer Bilddaten automatisch zu erkennen.

---

## ğŸ“Œ ProjektÃ¼bersicht

Dieses Projekt bietet eine **vollstÃ¤ndige Pipeline** zur Klassifikation von Modebildern, bestehend aus:
- ğŸ“¥ **Datenvorbereitung:** Laden und Vorverarbeiten der Fashion-MNIST-Bilder
- ğŸ— **Modellaufbau:** Ein CNN mit mehreren Convolutional- und Pooling-Schichten
- ğŸ¯ **Training & Optimierung:** Einsatz von **Early Stopping**, um Ãœberanpassung zu vermeiden
- ğŸ” **Fehlklassifikationsanalyse:** Anzeige falsch erkannter Bilder zur Verbesserung des Modells

Der **Fashion-MNIST-Datensatz** besteht aus **70.000** graustufigen Bildern von **10 KleidungsstÃ¼ck-Kategorien**. Die Herausforderung besteht darin, aus den Bildmerkmalen Muster zu erkennen und sie den richtigen Klassen zuzuordnen.

---

## ğŸ§  Modellarchitektur

Ein **Convolutional Neural Network (CNN)** ist besonders gut fÃ¼r Bildklassifikation geeignet, da es rÃ¤umliche Beziehungen in Bildern erfasst. Unser Modell besteht aus:

1. **Faltungsschichten (Convolutional Layers)** â€“ Extrahieren Merkmale aus den Bildern.
2. **Max-Pooling-Schichten** â€“ Reduzieren die BildgrÃ¶ÃŸe, um Rechenaufwand zu sparen.
3. **Dropout-Schicht** â€“ Verhindert Ãœberanpassung durch zufÃ¤lliges Ausschalten von Neuronen.
4. **Dense-Schichten** â€“ Treten in der Endphase zur Klassifikation auf.

```python
tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(10, activation='softmax')
])
```

Das Modell kann Bilder in **eine von 10 Klassen** einteilen, z. B. T-Shirt, Sneaker oder Tasche.

---

## ğŸ‹ï¸â€â™‚ï¸ Training des Modells

Das Modell wird mit dem **Adam-Optimizer** trainiert, einem weit verbreiteten Algorithmus fÃ¼r neuronale Netze, der sich an die Lernrate anpasst. 

- **Loss-Funktion:** `categorical_crossentropy` â€“ geeignet fÃ¼r mehrklassige Klassifikationen.
- **Batch-GrÃ¶ÃŸe:** 32 â€“ Verarbeitet 32 Bilder pro Berechnungsschritt.
- **Epochen:** 10 â€“ Das Modell sieht die gesamten Trainingsdaten 10-mal.
- **Early Stopping:** Beendet das Training, wenn sich die Validierungsgenauigkeit nicht verbessert.

```python
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.fit(train_images, train_labels_onehot, 
          epochs=10,  
          batch_size=32, 
          validation_split=0.1, 
          callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)])
```

Falls das Modell zu frÃ¼h stoppt, kann die Anzahl der Epochen erhÃ¶ht werden.

---

## ğŸ“Š Ergebnisse

Nach dem Training wird das Modell auf **unabhÃ¤ngigen Testdaten** geprÃ¼ft, um die GeneralisierungsfÃ¤higkeit zu bewerten.

```python
test_loss, test_accuracy = model.evaluate(test_images, test_labels_onehot, verbose=2)
print(f"Testgenauigkeit: {test_accuracy:.2f}")
```

### ğŸ“ˆ Testergebnisse

âœ… **Testgenauigkeit:** `0.91` (91%) â€“ Das Modell erkennt 91 % der Bilder korrekt.  
âœ… **Anzahl der Testbilder:** `10.000` â€“ Getrennt von den Trainingsdaten.  
âœ… **Fehlklassifizierte Bilder werden visualisiert** â€“ Um mÃ¶gliche Verbesserungen zu erkennen.

**Beispielhafte Konsolenausgabe:**
```
Testgenauigkeit: 0.91
313/313 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1s 4ms/step  
Zeige 10 falsch klassifizierte Bilder...
```

Ein Wert von **91% ist gut**, aber durch Anpassungen kann die Genauigkeit weiter verbessert werden.

---

## ğŸ–¼ï¸ Visualisierung der Vorhersagen

Ein Modell ist nur so gut wie seine FÃ¤higkeit, Vorhersagen zu erklÃ¤ren. Dieses Projekt zeigt:

- **10 zufÃ¤llig gewÃ¤hlte Bilder** mit vorhergesagten Labels.
- **Falsch klassifizierte Bilder**, um SchwÃ¤chen zu erkennen.

```python
show_predictions(model, test_images, test_labels_onehot, class_names, num_images=10)
show_misclassified_images(model, test_images, test_labels_onehot, class_names, num_images=10)
```

Diese Visualisierung hilft dabei, **hÃ¤ufige Fehlerquellen** des Modells zu erkennen.

---

## ğŸ“¦ Installation & AbhÃ¤ngigkeiten

### ğŸ”½ 1. Installiere die erforderlichen Bibliotheken
Damit das Skript ausgefÃ¼hrt werden kann, mÃ¼ssen einige Python-Bibliotheken installiert werden:
```bash
pip install tensorflow numpy matplotlib kagglehub
```

### ğŸ“‚ 2. Lade die Fashion-MNIST-Daten von Kaggle
Der Fashion-MNIST-Datensatz kann direkt Ã¼ber Kaggle heruntergeladen werden:
```python
import kagglehub
path = kagglehub.dataset_download("zalando-research/fashionmnist")
```

Dies speichert die Daten lokal, sodass sie fÃ¼r das Training genutzt werden kÃ¶nnen.

---

## ğŸ“œ Lizenz
ğŸ“ƒ Dieses Projekt steht unter der **MIT-Lizenz**. Weitere Details in der Datei `LICENSE`.

---

ğŸ› ï¸ **Erstellt von Ben MÃ¶lli**

